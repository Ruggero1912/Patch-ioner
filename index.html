<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="One Patch to Caption Them All: A Unified Zero-Shot Captioning Framework">
  <meta name="keywords" content="zero-shot image-captioning,region captioning,vision-language alignment,CLIP,DINOv2">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>One Patch to Caption Them All: A Unified Zero-Shot Captioning Framework</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/reshot-icon-ring-YCVRFT9QDM.svg"/>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script data-goatcounter="https://paciosoft.goatcounter.com/count"
        async src="//gc.zgo.at/count.js"></script>
  <script>
    document.addEventListener('DOMContentLoaded', function () {
      var carousels = bulmaCarousel.attach('#results-carousel', {
        slidesToScroll: 1,
        slidesToShow: 1,
        infinite: true
      });
    });
  </script>
</head>
<body>

  <nav class="navbar" role="navigation" aria-label="main navigation" style="flex-grow: 1; justify-content: center;">
    <div class="navbar-brand">
        <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
        </a>
    </div>
    <div class="navbar-menu">
        <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
            <a class="navbar-item" href="./index.html">
                <span class="icon">
                    <i class="fas fa-home"></i>
                </span>
                Home
            </a>
        </div>
    </div>
  </nav>
<!-- More Research -- >
  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
    <div class="navbar-menu">
      <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
        
        < !-- <a class="navbar-item" href="">
        <span class="icon">
            <i class="fas fa-home"></i>
        </span>
        </a> - ->
  
        < !-- <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link">
            Related Research
          </a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="">
              any
            </a>
          </div>
        </div> -- >
      </div>
  
    </div>
  </nav>
-->

<!-- More Research
<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="#">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>
      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="#">
            Project 1
          </a>
        </div>
      </div>
    </div>
  </div>
</nav>
-->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <header class="column has-text-centered">
          <h1 class="title is-1 publication-title">
            One Patch to Caption Them All
            <p class="title publication-title">A Unified Zero-Shot Captioning Framework</p>
            <!-- <p class="is-size-4 publication-awards"></p> -->
          </h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://www.linkedin.com/in/lorenzo-bianchi-893bb225a/">Lorenzo Bianchi</a><sup>*1,2</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/giacomo-pacini/">Giacomo Pacini</a><sup>*1,2</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/fabio-carrara-b28a2b111//">Fabio Carrara</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/nicola-messina-a33848164/">Nicola Messina</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="">Giuseppe Amato</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://fabriziofalchi.it">Fabrizio Falchi</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup><a href="https://www.isti.cnr.it/">ISTI CNR</a></span>
            <span class="author-block"><sup>2</sup>University of Pisa</span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">* Equal contribution</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href="#"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
              <span class="link-block">
                <a href="https://huggingface.co/spaces/Ruggero1912/Patch-ioner"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-robot"></i>
                  </span>
                  <span>Demo</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2510.02898"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- <span class="link-block">
                <a href="./assets/poster.png"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-image"></i>
                  </span>
                  <span>Poster</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/Ruggero1912/Patch-ioner"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://github.com/Ruggero1912/Patch-ioner/tree/main/Patch-ioner/eval-trace-captioning"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Trace Captioning Datasets</span>
                  </a>
              </span>
              <span class="link-block">
                <a href="https://huggingface.co/collections/Ruggero1912/patch-ioner-68e7ae42fed581777266b76a"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-balance-scale"></i>
                  </span>
                  <span>Models</span>
                  </a>
              </span>
              <!-- Video Link.
              <span class="link-block">
                <a href=""
                class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
            </div>
          </div>
        </header>
      </div>
    </div>
  </div>
</section>

<!-- Carousel.
<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-1"></div>
        <div class="item item-2"></div>
      </div>
    </div>
  </div>
</section>
-->

<!-- <section class="teaser">
  <div class="container is-max-desktop">
    < !-- Paper video. -- >
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video Summary</h2>
        <figure class="content publication-video image is-16by9">
          <iframe class="has-ratio" src="" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
        </figure>
      </div>
    </div>
    < !--/ Paper video. -- >
  </div>
</section> -->

<section class="section pt-0">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <!-- Teaser. -->
        <div class="hero-body">
          <img src="static/images/teaser.webp" alt="Patch-ioner architecture" class="teaser-image">
        </div>
      </div>
    </div>
  </div>
</section>
<section class="section pt-0 hero is-light">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <div class="content has-text-justified hero is-light">
          <h2 class="title is-3">Abstract</h2>
          <p>
          Zero-shot captioners are recently proposed models that utilize common-space vision-language representations to caption images without relying on paired image-text data. 
          To caption an image, they proceed by textually decoding a text-aligned image feature, but they limit their scope to global representations and whole-image captions. 
          </p>
          <p>
          We present Patch-ioner, a unified framework for zero-shot captioning that shifts from an image-centric to a patch-centric paradigm, enabling the captioning of arbitrary regions without the need of region-level supervision. 
          Instead of relying on global image representations, we treat individual patches as atomic captioning units and aggregate them to describe arbitrary regions, from single patches to non-contiguous areas and entire images. 
          We analyze the key ingredients that enable current latent captioners to work in our novel proposed framework. 
          Experiments demonstrate that backbones producing meaningful, dense visual features, such as DINO, are key to achieving state-of-the-art performance in multiple region-based captioning tasks. 
          Compared to other baselines and state-of-the-art competitors, our models achieve better performance on zero-shot dense, region-set, and a newly introduced trace captioning task, highlighting the effectiveness of patch-wise semantic representations for scalable caption generation.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

      <div class="column is-full-width">
        <h2 class="title is-2">Tasks</h2>
        <div class="content has-text-justified">
          <p>
            Local-understanding capabilities of our model enable it to solve many captioning tasks:

          </p>
        </div>
      </div>

    <div class="columns is-centered">

      <div class="column">
        <div class="content">
          <h3 class="title is-4">Patch Captioning</h3>
          <div class="side-by-side-images-containers">
          <img src="./static/images/patch-captioning/tennis-street-light-captions.jpg"
                 class="image-full-width"
            alt="Trace Captioning example on skyscrapers that are on the background of an image depicting giraffes"/>
          </div>
          <p>
            Patch Captioning consists in the task of generating a 
            caption for each patch of the image generated by the visual backbone. 
          </p>
          
        </div>
      </div>
      <div class="column">
        <div class="content">
          <h3 class="title is-4">Trace Captioning</h3>
          <div class="side-by-side-images-containers">
          <img src="./static/images/trace-captioning/giraffes-skyscrapers.jpg"
                 class="image-full-width"
            alt="Trace Captioning example on skyscrapers that are on the background of an image depicting giraffes"/>
          </div>
          <p>
            We define Trace Captioning as generating a caption for a region within an image specified by a mouse trace. 
            This task is particularly useful to obtain localized descriptions of images. For example, consider the understanding
             of image content by visually impaired users.
          </p>
          
        </div>
      </div>

      <div class="column">
        <div class="content">
          <h3 class="title is-4">Dense Captioning</h3>
          <div class="side-by-side-images-containers">
          <img src="./static/images/dense-captioning/clock-train-station.jpg"
                 class="image-full-width"
            alt="Dense Captioning example image: train station clock"/>
          </div>
          <p>
            requires locating salient regions in an 
            image and generating their descriptions. We focus on the 
            captioning of already defined boxes.
          </p>
          
        </div>
      </div>

      <div class="column">
        <div class="content">
          <h3 class="title is-4">Region-Set Captioning</h3>
          <div class="side-by-side-images-containers">
          <img src="./static/images/region-set-captioning/baby-stroller-two-people.jpg"
                 class="image-full-width"
            alt="Region-set Captioning: example image two people with a stroller"/>
          </div>
          <p>
           Consists of generating a single 
            caption for multiple regions within an image, where each 
            region is specified by a distinct bounding box.
          </p>
          
        </div>
      </div>

      <div class="column">
        <div class="content">
          <h3 class="title is-4">Image Captioning</h3>
          <div class="side-by-side-images-containers">
          <img src="./static/images/image-captioning/surfer-in-the-sea.jpg"
                 class="image-full-width"
            alt="Image Captioning: surfer in the sea example"/>
          </div>
          <p>
            involves generating a single caption
            that describes the entire image. To achieve this, we derive
            a global representation by aggregating the feature embeddings of all patches within the image.
          </p>
          
        </div>
      </div>
      
    </div>
  </div>
  </section>


  <section class="hero is-light is-small">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-full-width" style="padding-top: 40px;">
        <h2 class="title is-3">Qualitative Results</h2>
        <p>We report some predictions of our model and compare baselines from the finer (top) to the coarser (bottom)
          task. For trace captioning examples, the trace time is color-coded from start (red) to end (yellow). <b>DeCap</b> = DeCap applied on the whole
          image. <b>DeCap P</b> = DeCap applied on the same aggregation of patches used by our method. <b>DeCap C</b> = DeCap applied on cropped box.
          <b>ZeroCap</b> = ZeroCap applied to the whole image. <b>CLOSE</b> = CLOSE applied to the whole image. <b>GT</b> = ground-truth caption.</p>
      </div></div></div>
      <div class="hero-body">
      <div class="container">
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item item-1">
            <img src="./static/images/examples-window/examples1.webp" alt="inference examples" class="teaser-image">
          </div>
          <div class="item item-2">
            <img src="./static/images/examples-window/examples2.webp" alt="other inference examples" class="teaser-image">
          </div>
        </div>
      </div>
    </div>
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-full-width" style="padding-top: 10px; padding-bottom: 10px;">
      <p style="font-size: smaller;">Other Trace Captioning Examples <a href="./patch-captioning-examples/index.html">here</a>.</p>
    </div></div></div>
  </section>

<!-- Results -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Comparison with SOTA</h2>
        <div class="content has-text-justified">
          <p>
            We compare <b>Patch-ioner</b> with state-of-the-art zero-shot captioners and region-supervised backbones
            (<i>AlphaCLIP</i>, <i>RegionCLIP</i>) on trace, dense, region-set, and image captioning.
            Unlike these models, Patch-ioner is trained without region-level annotations.
            Our framework excels in <i>fine-grained regional tasks</i>, extends seamlessly to <i>context-aware
              region-set captioning</i>,
            and remains <i>competitive on whole-image captioning</i>.
          </p>
          <div class="columns is-centered">
            <div class="column">
              <figure>
                <img src="./static/images/results-table.webp" alt="Quantitative results table across tasks"
                  class="teaser-image">
                <figcaption class="has-text-centered is-size-7" style="margin-top:10px;">
                  Comparison of <b>Patch-ioner</b> (Talk2DINO, T2D) with zero-shot and region-supervised captioners.
                  Patch-ioner consistently outperforms whole-image and region-level baselines on local, fine-grained
                  tasks,
                  while achieving strong results on whole-image captioning.
                  Metrics: CIDEr (C), RefPAC (P), mean average precision (mAP), CLIP-Score (CLIP-S).
                </figcaption>
              </figure>
            </div>
          </div>
          <p>
            In trace and dense captioning, Patch-ioner surpasses whole-image and crop-based models.
            On region-set captioning, patch aggregation yields coherent captions that even outperform region-supervised
            backbones.
            For whole-image captioning, results are competitive with the strongest dedicated models, prioritizing
            semantic quality.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- Concurrent Work.
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>
        <div class="content has-text-justified">
          <p></p>
        </div>
      </div>
    </div>
  </div>
</section>
-->

<style>
.content pre {
  background-color: #272822;
  color: #f8f8f2;
  border-radius: 8px;
  padding: 1rem;
  overflow-x: auto;
}

.content code.python {
  color: #fde9ee;
  border-radius: 4px;
  padding: 0.15em 0.4em;
}

</style>

<section class="section hero">
  <div class="container is-max-desktop content" style="max-width: 90%;">
    <h2 class="title is-3">Installation and Checkpoints</h2>
    <p>
      You can try <b>Patch-ioner</b> directly in your browser using our
      <a href="https://huggingface.co/spaces/Ruggero1912/Patch-ioner" target="_blank">
        <b>Hugging Face Demo</b>
      </a>.
    </p>

    <p>
      To install locally create an empty python virtual environment (recommended), then:
    </p>

<pre><code class="python">pip install git+https://github.com/Ruggero1912/Patch-ioner.git
</code></pre>

    <p>
      All available model checkpoints are hosted on Hugging Face <a href="https://huggingface.co/collections/Ruggero1912/patch-ioner-68e7ae42fed581777266b76a" target="_blank"><b>here</b></a>
    </p>

    <p>
      Each model can be loaded through the from_config method, that can fetch the checkpoints weights from HuggingFace hub.  
      Example:
    </p>

<pre><code class="python">from patchioner import Patchioner
model = Patchioner.from_config("Ruggero1912/Patch-ioner_talk2dino_decap_COCO_Captions")
</code></pre>

  </div>
</section>


<section class="section hero is-light id="BibTeX">
  <div class="container is-max-desktop content" style="max-width: 90%;">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{bianchi2025patchcaptionallunified,
      title={One Patch to Caption Them All: A Unified Zero-Shot Captioning Framework}, 
      author={Lorenzo Bianchi and Giacomo Pacini and Fabio Carrara and Nicola Messina and Giuseppe Amato and Fabrizio Falchi},
      year={2025},
      eprint={2510.02898},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2510.02898}, 
}</code></pre>
  </div>
</section>

<div class="container is-max-desktop content">
    <h2 class="title">Acknowledgements</h2>
    <p>
      <img src="./static/images/fair.svg" class="ack-img" alt="FAIR Project Logo" width="200">
      This work has received financial support by the project FAIR – Future Artificial Intelligence Research - Spoke 1 (PNRR M4C2 Inv. 1.3 PE00000013) funded by the European Union - Next Generation EU.
    </p>
    <p>
        <img src="./static/images/muces.png" class="ack-img" alt="MUCES Project Logo" width="200">
      This work has received financial support by the European Union — Next Generation EU, Mission 4 Component 1
      CUP B53D23026090001 (a MUltimedia platform for Content Enrichment and Search in audiovisual archives — MUCES PRIN 2022 PNRR P2022BW7CW).
    </p>
</div>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <!-- <a class="icon-link" href="" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a> -->
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This website is borrowed from <a
              href="https://github.com/nerfies/nerfies.github.io">nerfies</a>.
          </p>
          <p>
            Dataset and images provided by <a href="http://cocodataset.org">COCO Dataset</a> (Common Objects in Context), licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>.
        </p>
        <p>
          This site collects anonymous visitor statistics with 
          <a href="https://www.goatcounter.com/" target="_blank" rel="noopener noreferrer">GoatCounter</a>. 
          No personal data is stored. See <a href="https://www.goatcounter.com/privacy" target="_blank" rel="noopener noreferrer">privacy policy</a>.
        </p>
        <p class="has-text-centered" style="margin-top: 10px;">
          ⭐ Enjoy our work? <a href="https://github.com/Ruggero1912/Patch-ioner" target="_blank">Star the repo</a> on GitHub to support us! ⭐
        </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
  <style>
  .ack-img{
    float: left;
    margin-right: 10px;
  }
</style>
</html>
